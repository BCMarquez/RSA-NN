{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior states:  {'WC60': [0.09575197931883855, 0.1889540474298701, 0.2797218201844803, 0.21709143364019776, 0.21848071942661343], 'WC95': [0.16247380630469407, 0.08032275710549394, 0.0844336204282914, 0.1697953184630545, 0.502974497698466], 'WC45': [0.10345675718238698, 0.3056392902565662, 0.1354679417560025, 0.3807190860046307, 0.07471692480041367], 'WC23': [0.262669574207323, 0.059119787035271376, 0.1406613443778739, 0.30325901045982057, 0.23429028391971113], 'WC39': [0.053857147829849086, 0.23278663214263423, 0.255734891167184, 0.36971835238714773, 0.08790297647318496], 'WC15': [0.39858949012218214, 0.39813622367008245, 0.10148025454043753, 0.07526360083551993, 0.0265304308317778], 'WC51': [0.019364399168817808, 0.5485646280525515, 0.07867218028069774, 0.0706187919996123, 0.28278000049832075], 'WC9': [0.18258063370289768, 0.21395498219331235, 0.20349937111486419, 0.19222539250594636, 0.20773962048297945], 'WC12': [0.02128201236437596, 0.34526981215215446, 0.33236711854179796, 0.009130289291596613, 0.291950767650075], 'WC24': [0.052302062507852715, 0.3139070540771824, 0.29575672404830183, 0.2976974113227466, 0.040336748043916563], 'WC16': [0.3097898862045896, 0.10044101646305999, 0.1844737731634995, 0.3100171219162611, 0.09527820225258987], 'WC32': [0.1040636688511918, 0.18360237999243467, 0.16179577520730237, 0.20983302840643722, 0.3407051475426339], 'WC0': [0.14568632613483945, 0.3174034550599687, 0.21246691893557113, 0.07180747738467362, 0.25263582248494715], 'WC76': [0.21609032440405446, 0.2508085636378193, 0.31672016002649217, 0.0614525163100541, 0.15492843562158], 'WC38': [0.35279606111769246, 0.08372152647158984, 0.2379128283385819, 0.21833213099121357, 0.10723745308092224], 'WC1': [0.4923232915374072, 0.09521751490485866, 0.3222159777024152, 0.02672650677162029, 0.0635167090836985], 'WC7': [0.19650888016694412, 0.24780615812854162, 0.030175346037633582, 0.2529331311807192, 0.27257648448616145], 'WC44': [0.2109374701262787, 0.31949485193810323, 0.06706500546846651, 0.2792144352180333, 0.12328823724911822], 'WC93': [0.1183992391296805, 0.2321609110827454, 0.11234290415670625, 0.19708136409391544, 0.3400155815369523], 'WC48': [0.3080695198076596, 0.19645064129136944, 0.10381869467344129, 0.3171697552889286, 0.0744913889386009], 'WC71': [0.1851366375854125, 0.017802467015115876, 0.2832304290100439, 0.477227111011438, 0.03660335537798976], 'WC20': [0.2546059013507137, 0.23137260009158392, 0.10379309526910399, 0.17540546054064993, 0.23482294274794843], 'WC57': [0.3076265179674798, 0.006403366843093552, 0.35370347434312016, 0.0036280586969306312, 0.3286385821493758], 'WC72': [0.04784002645571309, 0.010194900932569606, 0.136718814978985, 0.7087973038801301, 0.0964489537526022], 'WC62': [0.10304336918091489, 0.17732751812751557, 0.2160496769960506, 0.12566710821063115, 0.3779123274848877], 'WC88': [0.2514609817863746, 0.19070445381790713, 0.07545928936151147, 0.30395526664465106, 0.17842000838955574], 'WC66': [0.09045119609947644, 0.009646637440894465, 0.2082913967541743, 0.2377557319157502, 0.45385503778970465], 'WC2': [0.1993884882302638, 0.029249319422973877, 0.30779649925027613, 0.18184707901061067, 0.28171861408587556], 'WC70': [0.0780136860932762, 0.2656232157460964, 0.22396359361100418, 0.3449151456008205, 0.08748435894880284], 'WC29': [0.47251383164064054, 0.012087386557978978, 0.21152307329831913, 0.08155732107463802, 0.22231838742842336], 'WC19': [0.13593170992187836, 0.24475173707462194, 0.22591478486194788, 0.29042917308712246, 0.10297259505442927], 'WC17': [0.35885849381998225, 0.2739737168656185, 0.06688683493087787, 0.14622249007696217, 0.15405846430655937], 'WC53': [0.2707843006491118, 0.08655840584168412, 0.16805742957214007, 0.19480484361496583, 0.2797950203220982], 'WC78': [0.2118975241698879, 0.17845293807211685, 0.2834105055818997, 0.01832459374253731, 0.30791443843355837], 'WC36': [0.20825228352668046, 0.32130785679449503, 0.18920385005653265, 0.03806707347971648, 0.24316893614257537], 'WC96': [0.1406398175259554, 0.10810673707122867, 0.20572523098101902, 0.25327690387951346, 0.2922513105422833], 'WC21': [0.30036328282866825, 0.0010387287801173104, 0.1312339634118351, 0.498316319532679, 0.06904770544670032], 'WC5': [0.3621182129725476, 0.21379580253551478, 0.12705627131465094, 0.038944801778622716, 0.25808491139866396], 'WC55': [0.23645356152437402, 0.27627318803528217, 0.2184218295180753, 0.01568445841591096, 0.2531669625063577], 'WC41': [0.34309279460467373, 0.24403251931335826, 0.10285448555708197, 0.05626679449172324, 0.2537534060331627], 'WC68': [0.2848800060644522, 0.09789987722474504, 0.1500856744754701, 0.4391892693153538, 0.027945172919978892], 'WC73': [0.0018177841078495056, 0.1269526309812567, 0.3171336639747427, 0.0477106128022586, 0.5063853081338926], 'WC35': [0.26056588717216916, 0.07511653534300275, 0.2204856070078747, 0.20961734367452384, 0.23421462680242952], 'WC94': [0.510082601520954, 0.15494000909242475, 0.23238485874218312, 0.044816297021819974, 0.05777623362261825], 'WC87': [0.11408696731490446, 0.3780433897586567, 0.06979475021036446, 0.19943610123350258, 0.23863879148257186], 'WC56': [0.13444345610993705, 0.10541221669142839, 0.1497886118492896, 0.40817811396625614, 0.20217760138308882], 'WC25': [0.1153912209075835, 0.2906809421437016, 0.046146957552258866, 0.31441977808196697, 0.23336110131448912], 'WC98': [0.24784459099958212, 0.030283216202780905, 0.5177388453658859, 0.10113621412289557, 0.10299713330885552], 'WC43': [0.10433242527079435, 0.2648289393932271, 0.28143295269155505, 0.29714087255762295, 0.05226481008680038], 'WC13': [0.21053602189052842, 0.19387939095782006, 0.24187147342587564, 0.23640269018559248, 0.11731042354018341], 'WC77': [0.40561147055967733, 0.05065696922402891, 0.1644717336210045, 0.10569139985173925, 0.2735684267435499], 'WC49': [0.3049203151814607, 0.16432615957624253, 0.057078751045726565, 0.2020818203015805, 0.2715929538949898], 'WC92': [0.15164376694567624, 0.2552187478918229, 0.27706244073991765, 0.25850372452538645, 0.05757131989719672], 'WC58': [0.12525390078238458, 0.15133854293675117, 0.13698378057574268, 0.3073831009471784, 0.27904067475794314], 'WC81': [0.04996597356748502, 0.05916480958839914, 0.2741743817069178, 0.29976426916129245, 0.3169305659759055], 'WC54': [0.42673000288814456, 0.05579695244668195, 0.035038123218184385, 0.3979169556849897, 0.08451796576199934], 'WC63': [0.12249845369908015, 0.38457401374072536, 0.1219367751372229, 0.24149116728895792, 0.1294995901340136], 'WC37': [0.0212218418677879, 0.31685702408623007, 0.26264434763011213, 0.09640645571829941, 0.3028703306975706], 'WC69': [0.23574847683864342, 0.0914481370402345, 0.31887367617230805, 0.33841855889349765, 0.015511151055316336], 'WC34': [0.037566187430506603, 0.12787520095053803, 0.23814876884209876, 0.24825922378806278, 0.34815061898879385], 'WC6': [0.022968119423790418, 0.4103649814923694, 0.08858476015041289, 0.3624630524437981, 0.11561908648962926], 'WC64': [0.13139433623236063, 0.14119622984736116, 0.2330858517094067, 0.4361548421722533, 0.058168740038618154], 'WC91': [0.3001068403764542, 0.3119873988836533, 0.19827045573423152, 0.1655998575161967, 0.02403544748946444], 'WC28': [0.15895384347893474, 0.15807233160069195, 0.2816846258347717, 0.3919095475433905, 0.009379651542210925], 'WC26': [0.1906366144605445, 0.18193316793689696, 0.13642037039611024, 0.32390214769255865, 0.16710769951388962], 'WC61': [0.22311643013055546, 0.33545638900931607, 0.06328303463872904, 0.01242260215677015, 0.36572154406462926], 'WC10': [0.13362482686834948, 0.2529376053268848, 0.11434931321262425, 0.19645295090142212, 0.30263530369071934], 'WC89': [0.11887661595549665, 0.30200770130577653, 0.30121800953605443, 0.27029738360207883, 0.0076002896005935], 'WC80': [0.21440082571654673, 0.0058841222393410065, 0.32930438096945513, 0.010921002643763495, 0.43948966843089354], 'WC97': [0.4048267834174254, 0.15251801319842095, 0.04245989797932303, 0.2710680535866014, 0.12912725181822923], 'WC59': [0.07607969343144459, 0.11795570886530626, 0.36381010236857014, 0.1517526865244065, 0.29040180881027233], 'WC79': [0.1929265672608513, 0.26697656750119747, 0.19241058919456536, 0.05709347510946097, 0.2905928009339248], 'WC33': [0.1325410551200532, 0.43885889714838916, 0.029462538221616274, 0.2986393858939347, 0.10049812361600673], 'WC74': [0.22604076084974334, 0.1329312385324647, 0.27999865358095377, 0.1723800231599072, 0.188649323876931], 'WC82': [0.022810719826736648, 0.26198022687285366, 0.3239732515992541, 0.31656764614132565, 0.07466815555982984], 'WC83': [0.23040094240300546, 0.014244029396404628, 0.2010694043743931, 0.4736346139268055, 0.08065100989939143], 'WC52': [0.05329753886448927, 0.08950480765122905, 0.226307203245358, 0.2851351758049125, 0.34575527443401116], 'WC99': [0.02319095746641531, 0.32980541937342533, 0.10721697840318405, 0.29993179072331505, 0.23985485403366044], 'WC22': [0.16355564644470166, 0.36964688426255377, 0.1146463981848097, 0.15903380535205902, 0.1931172657558759], 'WC50': [0.23364193955225965, 0.044813995733010335, 0.2215335855063354, 0.2540751419649889, 0.2459353372434058], 'WC65': [0.20581090895494053, 0.25574129904798093, 0.1954873471594896, 0.07364508546585065, 0.26931535937173834], 'WC84': [0.10339631223043648, 0.29705736641418024, 0.2620547946823498, 0.11753136236943194, 0.21996016430360152], 'WC31': [0.27828698193655205, 0.28302808138330315, 0.2032511241642331, 0.1875562857465002, 0.04787752676941144], 'WC3': [0.2149464302404199, 0.2057480592429817, 0.20169001718618737, 0.1912437150342351, 0.18637177829617593], 'WC67': [0.12500670198085476, 0.18852150248905716, 0.27074283990791, 0.24686551504831478, 0.1688634405738633], 'WC11': [0.07409026994093358, 0.24469062900796792, 0.19053763694317213, 0.2344034425434189, 0.2562780215645075], 'WC85': [0.34399979973209527, 0.06506054487217673, 0.4911790675006934, 0.09923156123020767, 0.0005290266648268356], 'WC27': [0.2771299266034962, 0.007644453668669327, 0.2907082745293531, 0.09518248232034285, 0.32933486287813835], 'WC30': [0.1650445913349353, 0.09181284223827954, 0.22532527784417525, 0.27375891700261235, 0.24405837157999755], 'WC90': [0.18321422537466994, 0.45079545357155193, 0.046274710843009985, 0.06734130713768893, 0.25237430307307923], 'WC47': [0.06905026873972708, 0.21577594326938807, 0.23537769491957125, 0.23088389633878442, 0.24891219673252915], 'WC8': [0.10412526237856391, 0.14378183207227227, 0.2143187240292024, 0.28173121696197384, 0.25604296455798753], 'WC86': [0.17398281442326174, 0.34766029397669734, 0.1452604767342494, 0.05059706721601181, 0.28249934764977985], 'WC18': [0.12418387070943514, 0.03154886764076295, 0.3077642453917952, 0.3418885049679434, 0.19461451129006344], 'WC14': [0.4360352505934127, 0.10194030538603599, 0.30381728609323116, 0.1297180608937837, 0.028489097033536425], 'WC46': [0.34466997609409317, 0.0819207052584459, 0.21635980071663777, 0.07079126756631664, 0.2862582503645067], 'WC40': [0.02081701953680049, 0.20262228334187907, 0.3744405281930027, 0.3130553651151403, 0.08906480381317752], 'WC42': [0.3659494761052147, 0.1745055320867347, 0.08571963298571297, 0.12567442288541975, 0.24815093593691787], 'WC75': [0.2047942309323207, 0.1259370151488353, 0.32114365285966695, 0.024136816290749905, 0.32398828476842717], 'WC4': [0.47993439923128606, 0.024699963797451954, 0.13936083746059683, 0.11614402681915846, 0.23986077269150677]}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "import math\n",
    "import json\n",
    "\n",
    "# For each context, prior over the states\n",
    "prior_states = eval(open('irony/synthetic_prior_states.json', 'r').read())\n",
    "print(\"prior states: \", prior_states)\n",
    "# For each state, prior over valence+arousal combination\n",
    "prior_affect = eval(open('irony/prior_affect.json', 'r').read())\n",
    "\n",
    "# Prior over QUDs\n",
    "# hmmm was this ever calculated in the paper?\n",
    "prior_quds = {\n",
    "    \"state\":    0.3,\n",
    "    \"valence\":  0.3,\n",
    "    \"arousal\":  0.4,\n",
    "}\n",
    "\n",
    "\n",
    "states = [1,2,3,4,5]\n",
    "utterances = [1,2,3,4,5]\n",
    "quds = [ \"state\", \"valence\", \"arousal\"]\n",
    "valences = [\"positive\", \"negative\"]\n",
    "arousals = [\"high\", \"low\"]\n",
    "affects = [(v, a) for v in valences for a in arousals]\n",
    "contexts = list(prior_states.keys())\n",
    "\n",
    "rationality_factor = 1.0\n",
    "\n",
    "# the q function in the paper\n",
    "# 's' is the state of the world, 'A' reps the speaker's affect toward the state\n",
    "# this serves as a projection from full meaning spact to subset of speaker's interest\n",
    "def qud(q, s, A):\n",
    "    if q == \"state\": return s\n",
    "    if q == \"valence\": return A[0]\n",
    "    if q == \"arousal\": return A[1]\n",
    "    print(\"error\")\n",
    "\n",
    "\n",
    "def literal_listener(s, A, u):\n",
    "    if s != u:          #if state does not == utterance. This is the basic RSA that returns priors for true states.\n",
    "        return 0.0\n",
    "    else:\n",
    "        return prior_affect[s][A] #so the literal listener will return literally whatever the qud asks for. but what happens if the qud is the state? should we return the probability of a weather state happening? If it doesn't it probs won't change behavior because they're all uniform.\n",
    "\n",
    "\n",
    "# the U function in the paper, without the log\n",
    "# this models info gained by listener about topic of interest\n",
    "# where q is the intended QUD\n",
    "\n",
    "def exp_utility(u, s, A, q):\n",
    "    sum = 0.0\n",
    "    for sp in states:\n",
    "        for Ap in affects:\n",
    "            if qud(q, s, A) == qud(q, sp, Ap):\n",
    "                sum += literal_listener(sp, Ap, u)\n",
    "    return sum\n",
    "\n",
    "# the S function in the paper, normalized\n",
    "# \"the speaker S chooses an utterance according to a softmax decision rule\"\n",
    "# in the paper, it says the base is e. How come it's the the utility ftn^ rationality factior here?\n",
    "def speaker(u, s, A, q):\n",
    "    norm = 0.0\n",
    "    for up in utterances:\n",
    "        norm += math.pow(exp_utility(up, s, A, q), rationality_factor)\n",
    "    return math.pow(exp_utility(u, s, A, q), rationality_factor) / norm\n",
    "\n",
    "# the pragmatic L function in the paper, unnormalized\n",
    "# this is the ftn that models the ambiguity behind QUD, particularly it's held in the sum\n",
    "def unnorm_pragmatic_listener(s, A, u, context):\n",
    "    sum = 0.0\n",
    "    for q in quds:\n",
    "        sum += prior_quds[q] * speaker(u, s, A, q)\n",
    "    return prior_states[context][s] * prior_affect[s][A] * sum\n",
    "\n",
    "\n",
    "# the pragmatic L function in the paper, normalized\n",
    "def pragmatic_listener(s, A, u, context):\n",
    "    norm = 0.0\n",
    "    for sp in states:\n",
    "        for Ap in affects:\n",
    "            norm += unnorm_pragmatic_listener(sp, Ap, u, context)\n",
    "    return unnorm_pragmatic_listener(s, A, u, context) / norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "  CONTEXT: WC60\n",
      "----------------------\n",
      "--- utterance: 1 ----\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-69841f8a2496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mtotal_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  total_prob: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtotal_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-69841f8a2496>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpragmatic_listener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  s: %s, A: %s:\\t%f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3b2e47d063e9>\u001b[0m in \u001b[0;36mpragmatic_listener\u001b[0;34m(s, A, u, context)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mAp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mnorm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0munnorm_pragmatic_listener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0munnorm_pragmatic_listener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3b2e47d063e9>\u001b[0m in \u001b[0;36munnorm_pragmatic_listener\u001b[0;34m(s, A, u, context)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0msum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprior_quds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprior_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprior_affect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "output = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "def main():\n",
    "    for context in contexts:\n",
    "        print(\"----------------------\")\n",
    "        print(\"  CONTEXT: %s\" % context)\n",
    "        print(\"----------------------\")\n",
    "        for u in utterances:\n",
    "            print(\"--- utterance: %s ----\" % u)\n",
    "            total_prob = 0.0\n",
    "            for s in states:\n",
    "                for A in affects:\n",
    "                    prob = pragmatic_listener(s, A, u, context)\n",
    "                    output[context][u][s][A] = prob\n",
    "                    print(\"  s: %s, A: %s:\\t%f\" % (s, A, prob))\n",
    "                    total_prob += prob\n",
    "            print(\"  total_prob: %f\" % total_prob)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example on marginalizing over the affect to get the probability of a state. This is done over every utterance/context combination\n",
    "# for c in range(len(contexts)):\n",
    "#     for u in output[contexts[c]].keys():\n",
    "#         out = output[contexts[c]][u]\n",
    "#         y = [sum(affect.values()) for affect in out.values()]\n",
    "#         x = list(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "labels = [\"terrible\", \"bad\", \"neutral\", \"good\", \"amazing\"]\n",
    "\n",
    "\n",
    "for c in range(len(contexts)):\n",
    "    for u in output[contexts[c]].keys():\n",
    "        out = output[contexts[c]][u]\n",
    "        y = [sum(affect.values()) for affect in out.values()]\n",
    "        x = list(out.keys())\n",
    "\n",
    "        ax1 = plt.subplot2grid((9,5),(c,u-1))\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.plot(list(out.keys()),y)\n",
    "        plt.grid()\n",
    "        plt.xticks(list(out.keys()), labels) \n",
    "        plt.yticks(np.arange(0.0, 1.0, 0.25))\n",
    "\n",
    "\n",
    "fig.subplots_adjust(hspace=.5, wspace=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write output \n",
    "def ddict2dict(d):\n",
    "    '''\n",
    "    convert recursive defaultdict to dict\n",
    "    '''\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            d[k] = ddict2dict(v)\n",
    "    return dict(d)\n",
    "\n",
    "# for c in range(len(contexts)):\n",
    "#     for u in output[contexts[c]].keys():\n",
    "#         out = output[contexts[c]][u]\n",
    "#         y = [sum(affect.values()) for affect in out.values()]\n",
    "#         x = list(out.keys())\n",
    "\n",
    "for c in range(len(contexts)):\n",
    "    for u in output[contexts[c]].keys():\n",
    "        out = output[contexts[c]][u]\n",
    "        print([sum(affect.values()) for affect in out.values()])\n",
    "        #output[contexts[c]][u] = [sum(affect.values()) for affect in out.values()]\n",
    "        \n",
    "output = ddict2dict(output)\n",
    "with open('synthetic_fig_5_labels.json', 'w') as fp:\n",
    "    fp.write(str(output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
