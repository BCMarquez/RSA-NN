{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior states:  {'WC8': {1: 0.5555555555555556, 2: 0.35185185185185186, 3: 0.05555555555555555, 4: 0.018518518518518517, 5: 0.018518518518518517}, 'WC5': {1: 0.018518518518518517, 2: 0.018518518518518517, 3: 0.18518518518518517, 4: 0.5925925925925926, 5: 0.18518518518518517}, 'WC6': {1: 0.018518518518518517, 2: 0.14814814814814814, 3: 0.5185185185185185, 4: 0.2777777777777778, 5: 0.037037037037037035}, 'WC4': {1: 0.018518518518518517, 2: 0.018518518518518517, 3: 0.2222222222222222, 4: 0.6296296296296297, 5: 0.1111111111111111}, 'WC3': {1: 0.018518518518518517, 2: 0.018518518518518517, 3: 0.018518518518518517, 4: 0.16666666666666666, 5: 0.7777777777777778}, 'WC2': {1: 0.018518518518518517, 2: 0.018518518518518517, 3: 0.018518518518518517, 4: 0.05555555555555555, 5: 0.8888888888888888}, 'WC9': {1: 0.5555555555555556, 2: 0.35185185185185186, 3: 0.05555555555555555, 4: 0.018518518518518517, 5: 0.018518518518518517}, 'WC7': {1: 0.09259259259259259, 2: 0.4074074074074074, 3: 0.3333333333333333, 4: 0.14814814814814814, 5: 0.018518518518518517}, 'WC1': {1: 0.018518518518518517, 2: 0.018518518518518517, 3: 0.018518518518518517, 4: 0.07407407407407407, 5: 0.8703703703703703}}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "import math\n",
    "import json\n",
    "\n",
    "\n",
    "states = [1,2,3,4,5]\n",
    "utterances = [1,2,3,4,5]\n",
    "quds = [ \"state\", \"valence\", \"arousal\"]\n",
    "valences = [\"positive\", \"negative\"]\n",
    "arousals = [\"high\", \"low\"]\n",
    "affects = [(v, a) for v in valences for a in arousals]\n",
    "contexts = [\"WC1\", \"WC2\",\"WC3\",\"WC4\",\"WC5\",\"WC6\",\"WC7\",\"WC8\",\"WC9\"]\n",
    "\n",
    "# For each context, prior over the states\n",
    "prior_states = eval(open('irony/prior_states.json', 'r').read())\n",
    "print(\"prior states: \", prior_states)\n",
    "# For each state, prior over valence+arousal combination\n",
    "prior_affect = eval(open('irony/prior_affect.json', 'r').read())\n",
    "\n",
    "# Prior over QUDs\n",
    "# hmmm was this ever calculated in the paper?\n",
    "prior_quds = {\n",
    "    \"state\":    0.3,\n",
    "    \"valence\":  0.3,\n",
    "    \"arousal\":  0.4,\n",
    "}\n",
    "\n",
    "rationality_factor = 1.0\n",
    "\n",
    "# the q function in the paper\n",
    "# 's' is the state of the world, 'A' reps the speaker's affect toward the state\n",
    "# this serves as a projection from full meaning spact to subset of speaker's interest\n",
    "def qud(q, s, A):\n",
    "    if q == \"state\": return s\n",
    "    if q == \"valence\": return A[0]\n",
    "    if q == \"arousal\": return A[1]\n",
    "    print(\"error\")\n",
    "\n",
    "\n",
    "def literal_listener(s, A, u):\n",
    "    if s != u:          #if state does not == utterance. This is the basic RSA that returns priors for true states.\n",
    "        return 0.0\n",
    "    else:\n",
    "        return prior_affect[s][A] #so the literal listener will return literally whatever the qud asks for. but what happens if the qud is the state? should we return the probability of a weather state happening? If it doesn't it probs won't change behavior because they're all uniform.\n",
    "\n",
    "\n",
    "# the U function in the paper, without the log\n",
    "# this models info gained by listener about topic of interest\n",
    "# where q is the intended QUD\n",
    "\n",
    "def exp_utility(u, s, A, q):\n",
    "    sum = 0.0\n",
    "    for sp in states:\n",
    "        for Ap in affects:\n",
    "            if qud(q, s, A) == qud(q, sp, Ap):\n",
    "                sum += literal_listener(sp, Ap, u)\n",
    "    return sum\n",
    "\n",
    "# the S function in the paper, normalized\n",
    "# \"the speaker S chooses an utterance according to a softmax decision rule\"\n",
    "# in the paper, it says the base is e. How come it's the the utility ftn^ rationality factior here?\n",
    "def speaker(u, s, A, q):\n",
    "    norm = 0.0\n",
    "    for up in utterances:\n",
    "        norm += math.pow(exp_utility(up, s, A, q), rationality_factor)\n",
    "    return math.pow(exp_utility(u, s, A, q), rationality_factor) / norm\n",
    "\n",
    "# the pragmatic L function in the paper, unnormalized\n",
    "# this is the ftn that models the ambiguity behind QUD, particularly it's held in the sum\n",
    "def unnorm_pragmatic_listener(s, A, u, context):\n",
    "    sum = 0.0\n",
    "    for q in quds:\n",
    "        sum += prior_quds[q] * speaker(u, s, A, q)\n",
    "    return prior_states[context][s] * prior_affect[s][A] * sum\n",
    "\n",
    "\n",
    "# the pragmatic L function in the paper, normalized\n",
    "def pragmatic_listener(s, A, u, context):\n",
    "    norm = 0.0\n",
    "    for sp in states:\n",
    "        for Ap in affects:\n",
    "            norm += unnorm_pragmatic_listener(sp, Ap, u, context)\n",
    "    return unnorm_pragmatic_listener(s, A, u, context) / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "output = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "def main():\n",
    "    for context in contexts:\n",
    "        #print(\"----------------------\")\n",
    "        #print(\"  CONTEXT: %s\" % context)\n",
    "        #print(\"----------------------\")\n",
    "        for u in utterances:\n",
    "            #print(\"--- utterance: %s ----\" % u)\n",
    "            total_prob = 0.0\n",
    "            for s in states:\n",
    "                for A in affects:\n",
    "                    prob = pragmatic_listener(s, A, u, context)\n",
    "                    output[context][u][s][A] = prob\n",
    "                    #print(\"  s: %s, A: %s:\\t%f\" % (s, A, prob))\n",
    "                    total_prob += prob\n",
    "            #print(\"  total_prob: %f\" % total_prob)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example on marginalizing over the affect to get the probability of a state. This is done over every utterance/context combination\n",
    "# for c in range(len(contexts)):\n",
    "#     for u in output[contexts[c]].keys():\n",
    "#         out = output[contexts[c]][u]\n",
    "#         y = [sum(affect.values()) for affect in out.values()]\n",
    "#         x = list(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 45 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "labels = [\"terrible\", \"bad\", \"neutral\", \"good\", \"amazing\"]\n",
    "\n",
    "\n",
    "for c in range(len(contexts)):\n",
    "    for u in output[contexts[c]].keys():\n",
    "        out = output[contexts[c]][u]\n",
    "        y = [sum(affect.values()) for affect in out.values()]\n",
    "        x = list(out.keys())\n",
    "\n",
    "        ax1 = plt.subplot2grid((9,5),(c,u-1))\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.plot(list(out.keys()),y)\n",
    "        plt.grid()\n",
    "        plt.xticks(list(out.keys()), labels) \n",
    "        plt.yticks(np.arange(0.0, 1.0, 0.25))\n",
    "\n",
    "\n",
    "fig.subplots_adjust(hspace=.5, wspace=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0774852682314899, 0.025887017529188767, 0.017642718099620248, 0.04830869249768929, 0.8306763036420118]\n",
      "[0.03375715926366151, 0.09305849428153387, 0.03253254606674466, 0.08467644197778239, 0.7559753584102774]\n",
      "[0.027731109449354654, 0.03921352903527142, 0.12094234770911513, 0.13907921028854653, 0.6730338035177124]\n",
      "[0.007621430456218706, 0.010244480358502141, 0.013959558207616383, 0.18676564179605332, 0.7814088891816094]\n",
      "[0.004255022134088909, 0.0029695713636076716, 0.002193335810130856, 0.025370974062492425, 0.9652110966296803]\n",
      "[0.07705401304151718, 0.0257429396816549, 0.01754452506345554, 0.03602986774158341, 0.8436286544717891]\n",
      "[0.03392967566319452, 0.09353407092155923, 0.032698804064677504, 0.06383188652322867, 0.7760055628273401]\n",
      "[0.028310048075708708, 0.04003218458439887, 0.12346724476664626, 0.10648706113231202, 0.7017034614409341]\n",
      "[0.007857676930228912, 0.010562035229161385, 0.014392271780774908, 0.14441620408372313, 0.8227718119761116]\n",
      "[0.004195473004987872, 0.0029280121465381508, 0.0021626400268414995, 0.01876193003850723, 0.9719519447831254]\n",
      "[0.07971603816986376, 0.026632294429124733, 0.018150644910304537, 0.11182383105454882, 0.7636771914361581]\n",
      "[0.03292023979275574, 0.09075135507029025, 0.03172598764076044, 0.18579850555849514, 0.6588039119376983]\n",
      "[0.025158646132780904, 0.03557590446994834, 0.10972318774473634, 0.2838995838067553, 0.5456426778457789]\n",
      "[0.006625438565836583, 0.008905700267696276, 0.012135280357418527, 0.36530670447409885, 0.6070268763349498]\n",
      "[0.004580061367238679, 0.0031964155887123265, 0.002360883749318607, 0.06144536564199651, 0.9284172736527339]\n",
      "[0.09315903645054974, 0.031123459525144184, 0.25453797699233077, 0.4936851411615081, 0.1274943858704672]\n",
      "[0.025315398872649976, 0.06978706006702415, 0.29276434320433553, 0.5397596414986594, 0.07237355635733096]\n",
      "[0.009952502791252335, 0.014073463519054249, 0.5208644343727504, 0.42427379130300913, 0.03083580801393382]\n",
      "[0.00406987925645286, 0.005470600085340485, 0.0894536269086867, 0.8477366202719869, 0.05326927347753271]\n",
      "[0.011425444240784845, 0.007973794486781377, 0.07067367043532223, 0.5790650302113012, 0.3308620606258105]\n",
      "[0.09191515249162316, 0.03070789090695461, 0.20928276580893165, 0.45844077863477145, 0.20965341215771888]\n",
      "[0.026160259813544903, 0.07211609155995535, 0.2521124040251506, 0.5249630645573646, 0.12464818004398444]\n",
      "[0.010951387804416363, 0.015485949612989328, 0.477617584741064, 0.43939399400763385, 0.0565510838338964]\n",
      "[0.004192566103897654, 0.005635511778245747, 0.07679184492050851, 0.8219216102960443, 0.09145846690130376]\n",
      "[0.00972599147214069, 0.0067877498278973505, 0.0501345579708511, 0.4639371915738155, 0.46941450915529537]\n",
      "[0.07786814277985424, 0.20811945528383713, 0.49643706802751697, 0.18205274293301368, 0.03552259097577784]\n",
      "[0.016557023809844508, 0.3651425034893208, 0.4467787054359752, 0.1557436144517635, 0.01577815281309605]\n",
      "[0.006482242313850133, 0.0733303794143707, 0.7915793253086055, 0.12191341598986999, 0.00669463697330378]\n",
      "[0.006277600251946373, 0.06750517803609253, 0.32194884483808267, 0.5768799145033747, 0.02738846237050381]\n",
      "[0.018857657000620056, 0.10528576622930808, 0.27217552495704495, 0.42165214853625593, 0.18202890327677093]\n",
      "[0.2789646182140419, 0.4100763068495167, 0.22866409618888167, 0.0695689194429898, 0.012726059304569923]\n",
      "[0.05650497950279356, 0.6853770008259179, 0.19603850559647304, 0.056694825307467056, 0.005384688767348639]\n",
      "[0.03994923291105454, 0.2485591783929157, 0.627223173113726, 0.08014259617055422, 0.004125819411749517]\n",
      "[0.04211131637731195, 0.24906054661202737, 0.27767482127709875, 0.4127806230216489, 0.01837269271191309]\n",
      "[0.10779626517667928, 0.33101550242833183, 0.20003662593863153, 0.2570981923615009, 0.1040534140948566]\n",
      "[0.801823161287466, 0.16965779577669032, 0.018256812324735618, 0.004165848706926575, 0.006096381904181566]\n",
      "[0.34733429122162696, 0.6064152812923707, 0.03347339964678666, 0.007260443068240807, 0.005516584770974712]\n",
      "[0.41828665844120144, 0.37460627033371485, 0.18242533923739906, 0.017481864016440418, 0.00719986797124458]\n",
      "[0.4326393609765894, 0.3683085643161212, 0.07924305518697952, 0.08834974001183792, 0.031459279508472056]\n",
      "[0.586814139772635, 0.25937305608899586, 0.03024850226613557, 0.029157792545896233, 0.09440650932633737]\n",
      "[0.801823161287466, 0.16965779577669032, 0.018256812324735618, 0.004165848706926575, 0.006096381904181566]\n",
      "[0.34733429122162696, 0.6064152812923707, 0.03347339964678666, 0.007260443068240807, 0.005516584770974712]\n",
      "[0.41828665844120144, 0.37460627033371485, 0.18242533923739906, 0.017481864016440418, 0.00719986797124458]\n",
      "[0.4326393609765894, 0.3683085643161212, 0.07924305518697952, 0.08834974001183792, 0.031459279508472056]\n",
      "[0.586814139772635, 0.25937305608899586, 0.03024850226613557, 0.029157792545896233, 0.09440650932633737]\n"
     ]
    }
   ],
   "source": [
    "#write output \n",
    "def ddict2dict(d):\n",
    "    '''\n",
    "    convert recursive defaultdict to dict\n",
    "    '''\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            d[k] = ddict2dict(v)\n",
    "    return dict(d)\n",
    "\n",
    "# for c in range(len(contexts)):\n",
    "#     for u in output[contexts[c]].keys():\n",
    "#         out = output[contexts[c]][u]\n",
    "#         y = [sum(affect.values()) for affect in out.values()]\n",
    "#         x = list(out.keys())\n",
    "\n",
    "for c in range(len(contexts)):\n",
    "    for u in output[contexts[c]].keys():\n",
    "        out = output[contexts[c]][u]\n",
    "        print([sum(affect.values()) for affect in out.values()])\n",
    "        output[contexts[c]][u] = [sum(affect.values()) for affect in out.values()]\n",
    "        \n",
    "output = ddict2dict(output)\n",
    "with open('fig_5_labels.json', 'w') as fp:\n",
    "    fp.write(str(output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
